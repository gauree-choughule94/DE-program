{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebe9284a-bfb9-4dfb-93d6-de91981de3a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+\n|age|    name|salary|\n+---+--------+------+\n| 20|  Manish| 20000|\n| 25|  Nikita| 21000|\n| 16|  Pritam| 22000|\n| 35|Prantosh| 25000|\n| 67|  Vikash| 40000|\n+---+--------+------+\n\n"
     ]
    }
   ],
   "source": [
    "json_df = spark.read.format(\"json\").option(\"header\", 'true').option(\"inferSchema\", 'true').option(\"mode\", 'PERMISSIVE').load(\"/FileStore/tables/line_delimited_json.json\")\n",
    "\n",
    "json_df.show()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "735df96c-eee0-455a-b5c2-8d32a375ab40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------+------+\n|age|gender|    name|salary|\n+---+------+--------+------+\n| 20|  null|  Manish| 20000|\n| 25|  null|  Nikita| 21000|\n| 16|  null|  Pritam| 22000|\n| 35|  null|Prantosh| 25000|\n| 67|     M|  Vikash| 40000|\n+---+------+--------+------+\n\n"
     ]
    }
   ],
   "source": [
    "json_ef_df = spark.read.format(\"json\").option(\"header\", 'true').option(\"inferSchema\", 'true').option(\"mode\", 'PERMISSIVE').load(\"/FileStore/tables/line_deli_extra_fields.json\")\n",
    "\n",
    "json_ef_df.show()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b03897a9-821b-4283-ae91-5192be1b3a7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+\n|age|    name|salary|\n+---+--------+------+\n| 20|  Manish| 20000|\n| 25|  Nikita| 21000|\n| 16|  Pritam| 22000|\n| 35|Prantosh| 25000|\n| 67|  Vikash| 40000|\n+---+--------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# .option('multiline', 'true')\\                      # added\n",
    "\n",
    "json_mc_df = spark.read.format(\"json\")\\\n",
    ".option(\"header\", 'true')\\\n",
    ".option(\"inferSchema\", 'true')\\\n",
    ".option(\"mode\", 'PERMISSIVE')\\\n",
    ".option('multiline', 'true')\\\n",
    ".load(\"/FileStore/tables/multiline_correct.json\")\n",
    "\n",
    "json_mc_df.show()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a18d1bd-84c2-4c59-bde6-644a7961d395",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+\n|age|  name|salary|\n+---+------+------+\n| 20|Manish| 20000|\n+---+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# .option('multiline', 'true')\\                      # added\n",
    "\n",
    "json_mc_df = spark.read.format(\"json\")\\\n",
    ".option(\"header\", 'true')\\\n",
    ".option(\"inferSchema\", 'true')\\\n",
    ".option(\"mode\", 'PERMISSIVE')\\\n",
    ".option('multiline', 'true')\\\n",
    ".load(\"/FileStore/tables/multi_line_incorrect.json\")\n",
    "\n",
    "json_mc_df.show()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "489d8528-2aa0-43e8-a099-85c780963145",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+----+--------+------+\n|_corrupt_record                         |age |name    |salary|\n+----------------------------------------+----+--------+------+\n|null                                    |20  |Manish  |20000 |\n|null                                    |25  |Nikita  |21000 |\n|null                                    |16  |Pritam  |22000 |\n|null                                    |35  |Prantosh|25000 |\n|{\"name\":\"Vikash\",\"age\":67,\"salary\":40000|null|null    |null  |\n+----------------------------------------+----+--------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# .option('multiline', 'true')\\                      # added\n",
    "\n",
    "json_cj_df = spark.read.format(\"json\")\\\n",
    ".option(\"header\", 'true')\\\n",
    ".option(\"inferSchema\", 'true')\\\n",
    ".option(\"mode\", 'PERMISSIVE')\\\n",
    ".load(\"/FileStore/tables/corrupted_json.json\")\n",
    "\n",
    "json_cj_df.show(truncate=False)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1020b541-ffc9-411e-b1e0-0c32cba6f947",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n+--------------------+-------------------+-----+\n|       United States|            Romania|    1|\n|       United States|            Ireland|  264|\n|       United States|              India|   69|\n|               Egypt|      United States|   24|\n|   Equatorial Guinea|      United States|    1|\n|       United States|          Singapore|   25|\n|       United States|            Grenada|   54|\n|          Costa Rica|      United States|  477|\n|             Senegal|      United States|   29|\n|       United States|   Marshall Islands|   44|\n|              Guyana|      United States|   17|\n|       United States|       Sint Maarten|   53|\n|               Malta|      United States|    1|\n|             Bolivia|      United States|   46|\n|            Anguilla|      United States|   21|\n|Turks and Caicos ...|      United States|  136|\n|       United States|        Afghanistan|    2|\n|Saint Vincent and...|      United States|    1|\n|               Italy|      United States|  390|\n|       United States|             Russia|  156|\n+--------------------+-------------------+-----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "par_df = spark.read.parquet('/FileStore/tables/part_r_00000_1a9822ba_b8fb_4d8e_844a_ea30d0801b9e_gz.parquet')\n",
    "par_df.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "read_json_parquet",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}